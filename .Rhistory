g + geom_point()+geom_smooth("lm")
g + geom_point()+geom_smooth(method="lm")
g + geom_point()+geom_smooth(method="lm")+facet_grid(.~drv)
g + geom_point()+geom_smooth(method="lm")+facet_grid(.~drv)+ggtitle("Swirl Rules!")
g + geom_point(color="pink",size=4,alpha=1/2)
g + geom_point(color=drv,size=4,alpha=1/2)
g + geom_point(aes(color=drv),size=4,alpha=1/2)
g + geom_point(aes(color=drv),size=4,alpha=1/2)+labs(title="Swirl Rules!")+labs(x="Displacement",y="Hwy Mileage")
g + geom_point(aes(color=drv))+labs(title="Swirl Rules!")+labs(x="Displacement",y="Hwy Mileage")
g + geom_point(aes(color=drv),size=2,alpha=1/2)+labs(title="Swirl Rules!")+labs(x="Displacement",y="Hwy Mileage")+geom_smooth(size=4,linetype=3,method="lm")
g + geom_point(aes(color=drv),size=2,alpha=1/2)+labs(title="Swirl Rules!")+labs(x="Displacement",y="Hwy Mileage")+geom_smooth(size=4,linetype=3,method="lm",se=FALSE)
g + geom_point(aes(color=drv),size=2,alpha=1/2)+geom_smooth(size=4,linetype=3,method="lm",se=FALSE)
g+geom_point(aes(color=drv))+theme_bw(base_family = "Times")
plot(myx,myy,type="l",ylim=c(-3,3))
g<-ggplot(testdat,aes(x=myx,y=myy))
g+geom_line()
g+geom_line()+ylim(-3,3)
g+geom_line()+coord_cartesian(ylim=c(-3,3))
g<-ggplot(dataset,aes(x=displ,y=hwy,color=factor(year)))
g<-ggplot(mpg,aes(x=displ,y=hwy,color=factor(year)))
g+geom_point()
g+geom_point()+facet_grid(drv~cyl,margins=T)
g+geom_point()+facet_grid(drv~cyl,margins=TRUE)
g+geom_point()+facet_grid(drv~cyl,margins=TRUE)+geom_smooth(method="lm",se=FALSE,size=2,color="black")
g+geom_point()+facet_grid(drv~cyl,margins=TRUE)+geom_smooth(method="lm",se=FALSE,size=2,color="black")+labs(x="Displacement",y="Highway Mileage",title="Swirl Rules!")
str(diamonds)
qplot(price,data=diamonds)
range(diamonds$price)
qplot(price,data=diamonds,binwidth=18497/30)
brk
counts
qplot(price,data=diamonds,binwidth=18497/30,fill=cut)
qplot(price,data=diamonds,geom="density")
qplot(price,data=diamonds,geom="density",color=cut)
qplot(carat,price,data=diamonds)
qplot(carat,price,data=diamonds,shape=cut)
qplot(carat,price,data=diamonds,shape=cut,color=cut)
qplot(carat,price,data=diamonds,color=cut)
qplot(carat,price,data=diamonds,color=cut,geom=c("point","smooth"),method="lm")
qplot(carat,price,data=diamonds,color=cut,geom=c("point","smooth"),method="lm",facets=c(5,10))
qplot(carat,price,data=diamonds,color=cut,geom=c("point","smooth"),method="lm",facets=.~cut)
g<-ggplot(diamonds,aes(depth,price))
summary(g)
g+geom_point(alpha=1/3)
cutpoints=quantile(diamonds$carat,seq(0,1,length=4),na.rm=TRUE)
Type cutpoints <- quantile(diamonds$carat,seq(0,1,length=4),na.rm=TRUE)
cutpoints <- quantile(diamonds$carat,seq(0,1,length=4),na.rm=TRUE)
cutpoints
diamonds$car2<-cut(diamonds$carat,cutpoints)
g<-ggplot(diamonds,aes(depth,price))
g+geom_point(alpha=1/3)+facet_grid(cut~car2)
diamonds[myd,]
g+geom_point(alpha=1/3)+facet_grid(cut~car2)+geom_smooth(method="lm",size=3,color="pink")
ggplot(diamonds,aes(carat,price))+geom_boxplot()+facet_grid(.~cut)
swirl()
library(swirl)
install_course_github("https://github.com/swirldev/swirl_courses/tree/master/Getting_and_Cleaning_Data")
install_course_github("http://github.com/swirldev/swirl_courses/tree/master/Getting_and_Cleaning_Data")
install_from_swirl("Getting and Cleaning Data")
install_from_swirl("Regression Models")
install_from_swirl("Statistical Inference")
swirl()
mydf<-read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran<-tbl_df(mydf)
rm("mydf")
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran,package == "swirl")
filter(cran,r_version=="3.1.1",country=="US")
?Comparison
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,country=="US"|country=="IN")
filter(cran,size>100500&r_os=="linux-gnu")
filter(cran,size>100500 & r_os=="linux-gnu")
filter(cran,size>100500, r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_gb=size_mb/2^20)
mutate(cran3,size_gb=size_mb / 2^20)
cran3
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^20)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,correct_size=size-1000)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes=mean(size))
library(dplyr)
cran<-tbl_df(my_df)
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran,package)
by_package
summarize(by_package,mean(size))
?n
submit()
submit()
swirl()
submit()
rm(list=ls())
library(swirl)
swirl()
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran, package)
by_package
summarise(by_package,mean(size))
submit()
pack_sum
quantile(pack_sum$count,probs=0.99)
top_counts<-filter(pack_sum,count>679)
top_counts
View(top_counts)
top_counts_sorted<-arrange(top_counts,desc(counts))
top_counts_sorted<-arrange(top_counts,desc(count))
View(top_counts_sorted)
uantile(pack_sum$unique, probs=0.99)
quantile(pack_sum$unique, probs=0.99)
top_unique<-filter(pack_sum,unique > 465)
View(top_unique)
top_unique_sorted<-arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
cran %>%
select(ip_id,country,package,size) %>%
print
submit()
submit()
submit()
submit()
submit()
?unzip
?mtcars
library(MASS)
?shuttle
data(shuttle)
fit1<-glm(auto~wind,shuttle,family="binomial")
fit1<-glm(use~wind,shuttle,family="binomial")
summary(fit1)
exp(coef(fit1))
fit2<-glm(use~wind+magn,shuttle,family="binomial")
summary(fit2)
exp(coef(fit2))
data("InsectSprays")
data("InsectSprays")
fit3<-glm(count~spray,InsectSprays,poisson)
exp(coef(fit3))
fit3<-glm(count~spray,InsectSprays,family = "poisson")
exp(coef(fit3))
library(swirl)
install.packages("shiny")
install.packages('kernlab')
library(kernlab)
data(spam)
table(spam)
str(spam)
table(spam$type)
?prop.table
rm(list=ls())
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log10(1+training$Superplasticizer))
hist(training$Superplasticizer)
hist(training$Superplasticizer)
hist(log10(1+training$Superplasticizer))
range(training$Superplasticizer)
summary(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(train)
head(training)
headwithIL<-names(training) == '^IL%'
table(headwithIL)
headwithIL<-names(training) == 'IL%'
table(headwithIL)
headwithIL<-names(training) == 'IL*'
table(headwithIL)
headwithIL<-grepl("IL*",names(training))
table(headwithIL)
ILsets<-training[,headwithIL]
preProc<-preProcess(ILsets[,-1],method="pca")
preProc$numComp
preProc$std
names(Training[,headwithIL])
names(training[,headwithIL])
headwithIL<-grepl("^IL*",names(training))
table(headwithIL)
names(training[,headwithIL])
headwithIL<-grepl("^IL",names(training))
names(training[,headwithIL])
ILsets<-training[,headwithIL]
preProc<-preProcess(ILsets,method="pca")
preProc$pcaComp
preProc$numComp
?preProcess
preProc$std
preProc$x[,1]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
modelfit_all<-train(training$diagnosis~.,method="glm",data=training)
install.packages('caret')
install.packages("caret")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
modelfit_all<-train(training$diagnosis~.,method="glm",data=training)
install.packages('e1071', dependencies=TRUE)
modelfit_all<-train(training$diagnosis~.,method="glm",data=training)
confusionMatrix(testing$diagnosis,predict(modelfit_all,testing))
modelfit_pca<-train(training$diagnosis~.,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$diagnosis,predict(modelfit_pca,testing))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.8,
outcome=training$diagnosis)
preProc$rotation # 9
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
IL <- grep("^IL", colnames(training), value=TRUE)
args(preProcess)
args(preProcess())
args(preProcess
)
install.packages('devtools')
library(devtools)
install_github('slidify','ramnathv')
install_github('slidify','ramnathv/slidify')
install_github('ramnathv/slidify')
install_github('ramnathv/slidify')
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y<-factor(vowel.train$y)
vowel.test$y<-factor(vowel.test$y)
set.seed(33833)
modelfit5<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
varImp(modelfit5)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y<-factor(vowel.train$y)
vowel.test$y<-factor(vowel.test$y)
set.seed(33833)
modelfit5<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
varImp(modelfit5)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=.7,list=F)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
dim(training);dim(testing)
set.seed(125)
modelfit1<-train(Class~.,method='rpart',data=training)
print(modelfit1$finalModel)
plot(modelfit1$finalModel,uniform=T)
text(modelfit1$finalModel,use.n=T,all=T,cex=1)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelfit4<-glm(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,family = 'binomial')
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predict4<-predict(modelfit4,testSA)
predictt4<-predict(modelfit4,trainSA)
missClass(testSA$chd,predict4)
missClass(trainSA$chd,predictt4)
str(trainSA)
table(trainSA$chd)
summary(predict4$chd)
summary(predict4)
modelfit4
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelfit4<-glm(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,family = 'binomial')
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predict4<-predict(modelfit4,testSA)
predictt4<-predict(modelfit4,trainSA)
logittoprob<-function(logit){exp(logit)/(1+exp(logit))}
missClass(testSA$chd,logittoprob(predict4))
missClass(trainSA$chd,logittoprob(predictt4))
#1
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y<-factor(vowel.train$y)
vowel.test$y<-factor(vowel.test$y)
set.seed(33833)
modelfit1_rf<-train(y~.,methods="rf",data=vowel.train)
modelfit2_gbm<-train(y~.,methods="gbm",data=vowel.train)
predit1_rf<-predict(modelfit1_rf,vowel.test)
predit1_rf<-predict(modelfit1_rf,vowel.test)
predit2_gbm<-predict(modelfit2_gbm,vowel.test)
str(vowel.test)
checkAcuracy <- function (testvector,predictvector){
num_correct<-sum(testvector==predictvector)
accuracy<-num_correct/nrow(testvector)
}
checkAcuracy(vowel.test$y,predict1_rf)
predict1_rf<-predict(modelfit1_rf,vowel.test)
predict2_gbm<-predict(modelfit2_gbm,vowel.test)
checkAcuracy(vowel.test$y,predict1_rf)
checkAcuracy <- function (testvector,predictvector){
num_correct<-sum(testvector==predictvector)
accuracy<-num_correct/nrow(testvector)
return accuracy
}
checkAcuracy <- function (testvector,predictvector){
num_correct<-sum(testvector==predictvector)
accuracy<-num_correct/nrow(testvector)
return (accuracy)
}
checkAcuracy(vowel.test$y,predict1_rf)
table(vowel.test$y,predict1_rf)
sum(vowel.test$y==predict1_rf)
nrow(vowel.test$y)
length(vowel.test$y)
checkAcuracy <- function (testvector,predictvector){
num_correct<-sum(testvector==predictvector)
accuracy<-num_correct/length(testvector)
return (accuracy)
}
checkAcuracy(vowel.test$y,predict1_rf)
checkAcuracy(vowel.test$y,predict1_rf)
checkAcuracy(vowel.test$y,predict2_gbm)
checkAcuracy(predict1_rf,predict2_gbm)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y<-factor(vowel.train$y)
vowel.test$y<-factor(vowel.test$y)
set.seed(33833)
modelfit1_rf<-train(y~.,methods="rf",data=vowel.train)
modelfit2_gbm<-train(y~.,methods="gbm",data=vowel.train)
predict1_rf<-predict(modelfit1_rf,vowel.test)
predict2_gbm<-predict(modelfit2_gbm,vowel.test)
checkAcuracy <- function (testvector,predictvector){
num_correct<-sum(testvector==predictvector)
accuracy<-num_correct/length(testvector)
return (accuracy)
}
checkAcuracy(vowel.test$y,predict1_rf)
checkAcuracy(vowel.test$y,predict2_gbm)
checkAcuracy(predict1_rf,predict2_gbm)
setwd("H:/004 OpenCourses/Coursera/DS_Toolbox/DS_9_Data_Products/Project")
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
data(iris3)
data(iris)
head(iris)
head(iris3)
table(iris$Species)
?iris
sapply(iris,avg)
sapply(iris,mean)
sapply(iris,summary)
list.dirs(getwd())
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
str(iris)
shiny::runApp()
shiny::runApp()
shiny::runApp()
data.frame(c(1,2,3,4))
data.frame(t(c(1,2,3,4)))
(t(c(1,2,3,4)))
shiny::runApp()
library(caret)
data(iris)
modelfit<-train(Species~.,methods='gbm',data=iris)
head(iris)
predict(modelfit,dataframe(t(c(1,2,3,4,'')))))
predict(modelfit,dataframe(t(c(1,2,3,4,''))))
predict(modelfit,data.frame(t(c(1,2,3,4,''))))
dim(iris)
predict(modelfit,iris)
predict(modelfit,t(c(1,2,3,4)))
input_v<-iris[,1]
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
library(caret)
data(iris)
modelfit<-train(Species~.,methods='gbm',data=iris)
input_v<-iris[1,]
input_v[,1]<-1
input_v[,2]<-1
input_v[,3]<-1
input_v[,4]<-1
input_v[,5]<-''
predict(modelfit,input_v)
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
tapply(iris,iris$Species,summary)
tapply(iris$Sepal.Length,iris$Species,summary)
tapply(iris$Sepal.Width,iris$Species,summary)
tapply(iris$Petal.Length,iris$Species,summary)
tapply(iris$Petal.Width,iris$Species,summary)
shiny::runApp()
shiny::runApp()
install.packages("randomForest")
install.packages("randomForest")
shiny::runApp()
install.packages('e1071')
install.packages("e1071")
shiny::runApp()
